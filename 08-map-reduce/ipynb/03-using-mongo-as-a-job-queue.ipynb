{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from redis import Redis\n",
    "\n",
    "REDIS = Redis(host='this_redis')\n",
    "mongo_client = pymongo.MongoClient('this_mongo')\n",
    "corpus_db = mongo_client.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_pickle('data/corpus.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df_records = corpus.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_db.documents.drop()\n",
    "corpus_db.documents.insert_many(corpus_df_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_db.documents.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_db.documents.find_one({'tokens' : {'$exists': False}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `MAPPER`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(document):\n",
    "    return (document\n",
    "            .replace(',','')\n",
    "            .replace('.','')\n",
    "            .split())\n",
    "\n",
    "def MAPPER(document):\n",
    "    for word in tokenize(document):\n",
    "        yield (word, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = corpus_db.documents.find_one({'tokens' : {'$exists': False}})\n",
    "list(MAPPER(doc['sentence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unprocessed_filter = {'processed' : {'$exists': False}}\n",
    "doc = corpus_db.documents.find_one(unprocessed_filter)\n",
    "while doc:\n",
    "    id_filter = { '_id' : doc['_id'] }\n",
    "    tokens = list(MAPPER(doc['sentence']))\n",
    "    update = { '$set' : {'tokens' : tokens, 'processed' : 'tokenized'} }\n",
    "    corpus_db.documents.update_one(id_filter, update)\n",
    "    doc = corpus_db.documents.find_one({'tokens' : {'$exists': False}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_db.documents.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `COLLECTOR`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def COLLECTOR(document, vocabulary):\n",
    "    for token in doc['tokens']:\n",
    "        REDIS.sadd(vocabulary, token[0])\n",
    "        REDIS.rpush(*token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_filter = {'processed' : 'tokenized'}\n",
    "doc = corpus_db.documents.find_one(tokenized_filter)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while doc:\n",
    "    id_filter = { '_id' : doc['_id'] }\n",
    "    tokens = doc['tokens']\n",
    "    update = { '$set' : {'processed' : 'counted'} }\n",
    "    COLLECTOR(doc, 'corpus_vocab')\n",
    "    corpus_db.documents.update_one(id_filter, update)\n",
    "    doc = corpus_db.documents.find_one(tokenized_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = REDIS.smembers('corpus_vocab')\n",
    "list(vocabulary)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for word in list(vocabulary)[:5]:\n",
    "    print(REDIS.lrange(word, 0, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `REDUCER`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def REDUCER(word):\n",
    "    counts = [int(i) for i in REDIS.lrange(word, 0, -1)]\n",
    "    return sum(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "word_counts = []\n",
    "for word in vocabulary:\n",
    "    word_counts.append((word.decode(), REDUCER(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts.sort(key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "word_counts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
